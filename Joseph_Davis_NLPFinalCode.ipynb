{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c502f49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the necessary packages\n",
    "import nltk\n",
    "from nltk import FreqDist\n",
    "import csv\n",
    "import pandas\n",
    "import nltk.classify.util\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import movie_reviews\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e71cfaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156055</th>\n",
       "      <td>156056</td>\n",
       "      <td>8544</td>\n",
       "      <td>Hearst 's</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156056</th>\n",
       "      <td>156057</td>\n",
       "      <td>8544</td>\n",
       "      <td>forced avuncular chortles</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156057</th>\n",
       "      <td>156058</td>\n",
       "      <td>8544</td>\n",
       "      <td>avuncular chortles</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156058</th>\n",
       "      <td>156059</td>\n",
       "      <td>8544</td>\n",
       "      <td>avuncular</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156059</th>\n",
       "      <td>156060</td>\n",
       "      <td>8544</td>\n",
       "      <td>chortles</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156060 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        PhraseId  SentenceId  \\\n",
       "0              1           1   \n",
       "1              2           1   \n",
       "2              3           1   \n",
       "3              4           1   \n",
       "4              5           1   \n",
       "...          ...         ...   \n",
       "156055    156056        8544   \n",
       "156056    156057        8544   \n",
       "156057    156058        8544   \n",
       "156058    156059        8544   \n",
       "156059    156060        8544   \n",
       "\n",
       "                                                   Phrase  Sentiment  \n",
       "0       A series of escapades demonstrating the adage ...          1  \n",
       "1       A series of escapades demonstrating the adage ...          2  \n",
       "2                                                A series          2  \n",
       "3                                                       A          2  \n",
       "4                                                  series          2  \n",
       "...                                                   ...        ...  \n",
       "156055                                          Hearst 's          2  \n",
       "156056                          forced avuncular chortles          1  \n",
       "156057                                 avuncular chortles          3  \n",
       "156058                                          avuncular          2  \n",
       "156059                                           chortles          2  \n",
       "\n",
       "[156060 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load in the data that will be analyzed\n",
    "data=pandas.read_csv('train.tsv',sep='\\t')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "399ab8ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2325"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a column for phrase length, then select the longest phrase for each sentenceID. This way the original sentence\n",
    "#will be the one under investigation rather than all the split of sentences.\n",
    "PhraseLength=[]\n",
    "for row in data[\"Phrase\"]:\n",
    "    length=len(row)\n",
    "    PhraseLength.append(length)\n",
    "data[\"PhraseLength\"]=PhraseLength\n",
    "output = data[data['PhraseLength']==data.groupby('SentenceId')['PhraseLength'].transform(max)]\n",
    "sum(output[\"Sentiment\"]==3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce8661c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualize the spread of sentiments for the reviews\n",
    "Sentiments = list(output[\"Sentiment\"])\n",
    "plt.hist(Sentiments, color ='blue', edgecolor=\"Black\")\n",
    "plt.xlabel(\"Sentiment\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Reviews for each Sentiment\")\n",
    "plt.xticks(np.arange(0, 4.5, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c02e4203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8530"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The total reviews that will be investigated\n",
    "len(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9856db29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#long list of all full phrase strings\n",
    "for row in output:\n",
    "    Phraselist=list(output[\"Phrase\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc54f8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is a function that will filter the reviews and get rid of all characters that are not alphabetical numbers\n",
    "#which essentially just means this is a punctuation filter.\n",
    "def alpha_filter(w):\n",
    "  # pattern to match word of non-alphabetical characters\n",
    "  pattern = re.compile('^[^a-z]+$')\n",
    "  if (pattern.match(w)):\n",
    "    return True\n",
    "  else:\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ece0dfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Base function that will create word features for use in Naive-Bayes. This functinon will tokenize the words in a\n",
    "#string and make a dictionary where the word is the key and TRUE is the value.\n",
    "def create_word_features(words):\n",
    "    my_dict = dict([(word, True) for word in words])\n",
    "    return my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c31e617b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': True, 'quick': True, 'Brown': True, 'a': True, 'fox': True, '.': True}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example of the word feature function when no filtering is done. Notice punctuation, capitalization, and stop\n",
    "#words are not filter from the example sentence.\n",
    "create_word_features([\"the\", \"quick\", \"Brown\", \"quick\", \"a\", \"fox\", \".\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6df13efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = data[data['PhraseLength']==data.groupby('SentenceId')['PhraseLength'].transform(max)]\n",
    "Sent0=output[output[\"Sentiment\"]==0]\n",
    "Sent1=output[output[\"Sentiment\"]==1]\n",
    "Sent2=output[output[\"Sentiment\"]==2]\n",
    "Sent3=output[output[\"Sentiment\"]==3]\n",
    "Sent4=output[output[\"Sentiment\"]==4]\n",
    "for row in Sent0:\n",
    "    Phraselist0=list(Sent0[\"Phrase\"])\n",
    "for row in Sent1:\n",
    "    Phraselist1=list(Sent1[\"Phrase\"])\n",
    "for row in Sent2:\n",
    "    Phraselist2=list(Sent2[\"Phrase\"])\n",
    "for row in Sent3:\n",
    "    Phraselist3=list(Sent3[\"Phrase\"])\n",
    "for row in Sent4:\n",
    "    Phraselist4=list(Sent4[\"Phrase\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b840c51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the baseline word feature to create lists for each sentiment, however the list will be a list of tuples where\n",
    "#one part of the list is a dictionary with the word:True as seen above and the second part of the tuple will be\n",
    "#the sentiment number it was rated as\n",
    "Sent0 = []\n",
    "for review in Phraselist0:\n",
    "    words=review.split()\n",
    "    Sent0.append((create_word_features(words), \"0\"))\n",
    "    \n",
    "Sent1 = []\n",
    "for review in Phraselist1:\n",
    "    words=review.split()\n",
    "    Sent1.append((create_word_features(words), \"1\"))\n",
    "    \n",
    "Sent2 = []\n",
    "for review in Phraselist2:\n",
    "    words=review.split()\n",
    "    Sent2.append((create_word_features(words), \"2\"))\n",
    "    \n",
    "Sent3 = []\n",
    "for review in Phraselist3:\n",
    "    words=review.split()\n",
    "    Sent3.append((create_word_features(words), \"3\"))\n",
    "    \n",
    "Sent4 = []\n",
    "for review in Phraselist4:\n",
    "    words=review.split()\n",
    "    Sent4.append((create_word_features(words), \"4\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e3a9ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8530\n"
     ]
    }
   ],
   "source": [
    "#The lists of tuples are combined to one long list and shuffled randomly. It is then sampled into training and testing\n",
    "#Sets, the combined set has a length of 8530, so using the first 7000 is roughly a 14:3 split or roughly 80/20\n",
    "NBset=Sent0+Sent1+Sent2+Sent3+Sent4\n",
    "random.shuffle(NBset)\n",
    "print(len(NBset))\n",
    "training=NBset[:7000]\n",
    "testing=NBset[7000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "81a62e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38.43137254901961\n"
     ]
    }
   ],
   "source": [
    "#A classifier is created on the training data using Naive Bayes. The model is then applied to the testing set\n",
    "#and compared to the true values of the testing set. This gave an accuracy of 33.87%, however this will change\n",
    "#each time it is run. So anywhere from around 30-35% accuracy is expected.\n",
    "classifier = NaiveBayesClassifier.train(training)\n",
    "accuracy = nltk.classify.util.accuracy(classifier, testing)\n",
    "print(accuracy * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8c38eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the same word feature function from before, however this time stop words are removed. Various punctuation\n",
    "#is removed, and all words are made lowercase.\n",
    "def create_word_features_filtered(words):\n",
    "    stopwords1=nltk.corpus.stopwords.words('english')\n",
    "    s=['\\'s', '.', ',']\n",
    "    newwords=[x.lower() for x in words]\n",
    "    stopwords=stopwords1+s\n",
    "    useful_words = [word for word in newwords if word not in stopwords]\n",
    "    my_dict = dict([(word, True) for word in useful_words])\n",
    "    return my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1324837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'quick': True, 'brown': True, 'fox': True}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example of the filter in action, the Brown is made lowerase, the punctuation is removed and so are the stopwords\n",
    "create_word_features_filtered([\"the\", \"quick\", \"Brown\", \"quick\", \"a\", \"fox\", \".\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ee1be51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recreating the same list as before, with the tuple of a dictionary and the corresponding sentiment however\n",
    "#this time the new function with more filtering was done.\n",
    "Sent0 = []\n",
    "for review in Phraselist0:\n",
    "    words=review.split()\n",
    "    Sent0.append((create_word_features_filtered(words), 0))\n",
    "    \n",
    "Sent1 = []\n",
    "for review in Phraselist1:\n",
    "    words=review.split()\n",
    "    Sent1.append((create_word_features_filtered(words), 1))\n",
    "    \n",
    "Sent2 = []\n",
    "for review in Phraselist2:\n",
    "    words=review.split()\n",
    "    Sent2.append((create_word_features_filtered(words), 2))\n",
    "    \n",
    "Sent3 = []\n",
    "for review in Phraselist3:\n",
    "    words=review.split()\n",
    "    Sent3.append((create_word_features_filtered(words), 3))\n",
    "    \n",
    "Sent4 = []\n",
    "for review in Phraselist4:\n",
    "    words=review.split()\n",
    "    Sent4.append((create_word_features_filtered(words), 4))\n",
    "    \n",
    "NBset=Sent0+Sent1+Sent2+Sent3+Sent4\n",
    "random.shuffle(NBset)\n",
    "len(NBset)\n",
    "training=NBset[:7000]\n",
    "testing=NBset[7000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f7f7d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.55555555555556\n"
     ]
    }
   ],
   "source": [
    "#The same Naive Bayes classifier was used and the accuracy was found to be 34.71%, slightly better however note\n",
    "#that this will fluctuate.\n",
    "classifier = NaiveBayesClassifier.train(training)\n",
    "accuracy = nltk.classify.util.accuracy(classifier, testing)\n",
    "print(accuracy * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3abaad80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                   worst = True                0 : 3      =     18.0 : 1.0\n",
      "                     bad = True                0 : 4      =     16.7 : 1.0\n",
      "                       ? = True                2 : 4      =     15.9 : 1.0\n",
      "                  moving = True                4 : 0      =     15.7 : 1.0\n",
      "                    dull = True                0 : 3      =     15.3 : 1.0\n",
      "                 imagine = True                0 : 3      =     15.3 : 1.0\n",
      "            entertaining = True                4 : 0      =     15.2 : 1.0\n",
      "                  stupid = True                0 : 2      =     14.1 : 1.0\n",
      "                    mess = True                0 : 4      =     14.1 : 1.0\n",
      "                    loud = True                0 : 3      =     13.9 : 1.0\n",
      "              thoughtful = True                4 : 1      =     13.1 : 1.0\n",
      "                touching = True                4 : 1      =     13.1 : 1.0\n",
      "                    best = True                4 : 0      =     12.9 : 1.0\n",
      "                   worse = True                0 : 3      =     12.4 : 1.0\n",
      "                   heart = True                4 : 0      =     12.4 : 1.0\n",
      "                    warm = True                4 : 1      =     11.9 : 1.0\n",
      "               wonderful = True                4 : 1      =     11.9 : 1.0\n",
      "                    flat = True                1 : 3      =     11.7 : 1.0\n",
      "                    plot = True                0 : 4      =     11.4 : 1.0\n",
      "                    less = True                2 : 4      =     11.1 : 1.0\n",
      "                      tv = True                1 : 3      =     11.0 : 1.0\n",
      "                   money = True                0 : 3      =     11.0 : 1.0\n",
      "             beautifully = True                4 : 1      =     10.9 : 1.0\n",
      "                   smart = True                4 : 2      =     10.8 : 1.0\n",
      "                 purpose = True                0 : 1      =     10.3 : 1.0\n",
      "                    fare = True                4 : 3      =     10.3 : 1.0\n",
      "                    fact = True                0 : 2      =      9.9 : 1.0\n",
      "                 minutes = True                0 : 4      =      9.9 : 1.0\n",
      "                    year = True                4 : 2      =      9.8 : 1.0\n",
      "                terrific = True                3 : 1      =      9.7 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Showing which features of classifier are most informative\n",
    "print(classifier.show_most_informative_features(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c768fcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using only the top 2000 most frequently occuring words to train (experiment 2)\n",
    "#This time the most frequent 2000 words were collected.\n",
    "Phraselist\n",
    "biglist=\" \".join(Phraselist)\n",
    "fdist = FreqDist(word.lower() for word in word_tokenize(biglist))\n",
    "frequentwords=fdist.most_common(2000)\n",
    "word_features = [word for (word, freq) in frequentwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "15f9d96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A new function will create a features output with V_word where word is a word in the most frequent 2000 words.\n",
    "#It will be marked true if it appears in the review and it will be marked false if it does not. Again the associated\n",
    "#sentiment will paired with these long dictionaries. Most V_word will be false as the reviews are short.\n",
    "def document_features(document, word_features):\n",
    "\tdocument_words = set(document)\n",
    "\tfeatures = {}\n",
    "\tfor word in word_features:\n",
    "\t\tfeatures['V_%s' % word] = (word in document_words)\n",
    "\treturn features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "deed3eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['Nothing', 'about', 'the', 'film', '--', 'with', 'the', 'possible', 'exception', 'of', 'Elizabeth', 'Hurley', \"'s\", 'breasts', '--', 'is', 'authentic', '.'], 0)\n"
     ]
    }
   ],
   "source": [
    "#This simply creates a list of tuples, where the tuple is the tokenized phrase in a list and the sentiment. The list\n",
    "#of tuples is then shuffled so training and testing data can be pulled.\n",
    "phrasesent=list(zip(output.Phrase,output.Sentiment))\n",
    "phrasesent[0]\n",
    "tuples=[]\n",
    "somelist=[]\n",
    "hello=[]\n",
    "for review in phrasesent:\n",
    "    somelist=(review[0].split(), review[1])\n",
    "    hello=tuple(somelist)\n",
    "    tuples.append(hello)\n",
    "random.shuffle(tuples)\n",
    "print(tuples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2472625f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8530"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The featureset are again 8530 long so this will need to be split\n",
    "featuresets = [(document_features(d, word_features), c) for (d,c) in tuples]\n",
    "len(featuresets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "707152f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39\n"
     ]
    }
   ],
   "source": [
    "#This time significantly more training data (over 8000) will be used and tested on much less testing data (500)\n",
    "#Again naive bayes is used and compared to the true values. It returned an accuarcy of 36.4%\n",
    "train_set, test_set = featuresets[500:], featuresets[:500]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print (nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "df3e6fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                   V_bad = True                0 : 4      =     25.2 : 1.0\n",
      "                  V_dull = True                0 : 3      =     19.2 : 1.0\n",
      "                 V_worst = True                0 : 3      =     19.2 : 1.0\n",
      "                     V_? = True                2 : 4      =     17.4 : 1.0\n",
      "            V_thoughtful = True                4 : 1      =     16.7 : 1.0\n",
      "              V_touching = True                4 : 1      =     16.7 : 1.0\n",
      "                V_moving = True                4 : 0      =     15.0 : 1.0\n",
      "                  V_mess = True                0 : 4      =     14.6 : 1.0\n",
      "                  V_best = True                4 : 0      =     14.2 : 1.0\n",
      "                 V_worse = True                0 : 3      =     13.5 : 1.0\n",
      "                 V_heart = True                4 : 0      =     13.3 : 1.0\n",
      "             V_hilarious = True                4 : 1      =     13.2 : 1.0\n",
      "                  V_flat = True                1 : 3      =     12.9 : 1.0\n",
      "                  V_less = True                1 : 4      =     12.5 : 1.0\n",
      "                V_stupid = True                0 : 2      =     12.5 : 1.0\n",
      "                  V_ugly = True                0 : 2      =     12.5 : 1.0\n",
      "             V_wonderful = True                4 : 2      =     12.3 : 1.0\n",
      "                V_deeply = True                4 : 1      =     12.1 : 1.0\n",
      "            V_engrossing = True                4 : 1      =     12.1 : 1.0\n",
      "              V_terrific = True                4 : 1      =     12.1 : 1.0\n",
      "             V_contrived = True                0 : 3      =     12.1 : 1.0\n",
      "               V_lacking = True                0 : 3      =     12.1 : 1.0\n",
      "                 V_money = True                0 : 3      =     12.1 : 1.0\n",
      "           V_pretentious = True                0 : 3      =     12.1 : 1.0\n",
      "                  V_fact = True                0 : 2      =     11.5 : 1.0\n",
      "                 V_grace = True                4 : 3      =     11.5 : 1.0\n",
      "           V_fascinating = True                4 : 0      =     11.0 : 1.0\n",
      "              V_gorgeous = True                4 : 1      =     10.9 : 1.0\n",
      "                V_honest = True                4 : 1      =     10.9 : 1.0\n",
      "                  V_warm = True                4 : 1      =     10.9 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#A visual of the most defining features\n",
    "print(classifier.show_most_informative_features(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f0815cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.362\n"
     ]
    }
   ],
   "source": [
    "#Using the top 4000 words\n",
    "biglist=\" \".join(Phraselist)\n",
    "fdist = FreqDist(word.lower() for word in word_tokenize(biglist))\n",
    "frequentwords=fdist.most_common(4000)\n",
    "word_features = [word for (word, freq) in frequentwords]\n",
    "phrasesent=list(zip(output.Phrase,output.Sentiment))\n",
    "tuples=[]\n",
    "somelist=[]\n",
    "hello=[]\n",
    "for review in phrasesent:\n",
    "    somelist=(review[0].split(), review[1])\n",
    "    hello=tuple(somelist)\n",
    "    tuples.append(hello)\n",
    "random.shuffle(tuples)\n",
    "featuresets = [(document_features(d, word_features), c) for (d,c) in tuples]\n",
    "train_set, test_set = featuresets[500:], featuresets[:500]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print (nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8e449c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                   V_bad = True                0 : 4      =     26.4 : 1.0\n",
      "                 V_worst = True                0 : 3      =     20.1 : 1.0\n",
      "                     V_? = True                2 : 4      =     17.6 : 1.0\n",
      "            V_thoughtful = True                4 : 1      =     16.6 : 1.0\n",
      "             V_wonderful = True                4 : 1      =     16.6 : 1.0\n",
      "                  V_dull = True                0 : 3      =     15.6 : 1.0\n",
      "                V_moving = True                4 : 0      =     15.4 : 1.0\n",
      "                  V_best = True                4 : 0      =     14.5 : 1.0\n",
      "              V_touching = True                4 : 1      =     14.4 : 1.0\n",
      "                 V_heart = True                4 : 0      =     14.3 : 1.0\n",
      "                  V_flat = True                1 : 3      =     13.6 : 1.0\n",
      "             V_contrived = True                0 : 3      =     13.6 : 1.0\n",
      "                 V_worse = True                0 : 3      =     13.6 : 1.0\n",
      "                V_deeply = True                4 : 1      =     13.2 : 1.0\n",
      "                  V_mess = True                0 : 4      =     13.1 : 1.0\n",
      "                  V_ugly = True                0 : 2      =     12.7 : 1.0\n",
      "                  V_less = True                1 : 4      =     12.6 : 1.0\n",
      "               V_lacking = True                0 : 3      =     12.1 : 1.0\n",
      "           V_pretentious = True                0 : 3      =     12.1 : 1.0\n",
      "                 V_tired = True                0 : 3      =     12.1 : 1.0\n",
      "            V_delightful = True                4 : 1      =     12.1 : 1.0\n",
      "                V_honest = True                4 : 1      =     12.1 : 1.0\n",
      "              V_terrific = True                4 : 1      =     12.1 : 1.0\n",
      "                V_stupid = True                0 : 2      =     11.7 : 1.0\n",
      "                 V_grace = True                4 : 3      =     11.4 : 1.0\n",
      "            V_engrossing = True                4 : 1      =     10.9 : 1.0\n",
      "                  V_form = True                4 : 1      =     10.9 : 1.0\n",
      "            V_amateurish = True                0 : 3      =     10.7 : 1.0\n",
      "            V_depressing = True                0 : 3      =     10.7 : 1.0\n",
      "                V_devoid = True                0 : 3      =     10.7 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(classifier.show_most_informative_features(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "44cc8306",
   "metadata": {},
   "outputs": [],
   "source": [
    "#negation words\n",
    "negationwords = ['no', 'not', 'never', 'none', 'nowhere', 'nothing', 'noone','rather', 'hardly', 'scarcely', 'rarely', 'seldom', 'neither', 'nor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9d621015",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is a function that will include negation words into the formula. Instead of having \"nothing good\" being split\n",
    "#into \"nothing\" \"good\" and potentially missing the negation importance of the words \"nothing\" this function will\n",
    "#Add V_NOT_word to the feature set if it sees it appear in the reviews. \n",
    "def NOT_features(document, word_features, negationwords):\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['V_{}'.format(word)] = False\n",
    "        features['V_NOT{}'.format(word)] = False\n",
    "    # go through document words in order\n",
    "    for i in range(0, len(document)):\n",
    "        word = document[i]\n",
    "        if ((i + 1) < len(document)) and ((word in negationwords) or (word.endswith(\"n't\"))):\n",
    "            i += 1\n",
    "            features['V_NOT{}'.format(document[i])] = (document[i] in word_features)\n",
    "        else:\n",
    "            features['V_{}'.format(word)] = (word in word_features)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3a399e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "#An example of this in action, this will read the reviews in and tell if not good appears in the first review\n",
    "#Also note that NOT_featuresets is created which is a featureset however, the negation will be accounted for\n",
    "#because of the function described above.\n",
    "NOT_featuresets = [(NOT_features(d, word_features, negationwords), c) for (d, c) in tuples]\n",
    "# show the values of a couple of example features\n",
    "print(NOT_featuresets[0][0]['V_NOTgood'])\n",
    "print(NOT_featuresets[0][0]['V_always'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c10c0e22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.371"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training and testing sets created from the negation featureset. The accuracy was found to be 39.2% which is an\n",
    "#increase. Note that more data was used for testing and less for training than before and the accuracy will fluctuate.\n",
    "train_set, test_set = NOT_featuresets[1000:], NOT_featuresets[:1000]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "nltk.classify.accuracy(classifier, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "da2cb5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                   V_bad = True                0 : 4      =     25.3 : 1.0\n",
      "                  V_best = True                4 : 0      =     19.4 : 1.0\n",
      "                 V_worst = True                0 : 3      =     19.1 : 1.0\n",
      "                     V_? = True                2 : 4      =     17.4 : 1.0\n",
      "             V_wonderful = True                4 : 1      =     16.6 : 1.0\n",
      "                V_always = True                4 : 1      =     15.5 : 1.0\n",
      "             V_beautiful = True                4 : 1      =     15.5 : 1.0\n",
      "                V_moving = True                4 : 0      =     14.9 : 1.0\n",
      "                  V_dull = True                0 : 3      =     14.9 : 1.0\n",
      "                 V_heart = True                4 : 0      =     14.4 : 1.0\n",
      "            V_thoughtful = True                4 : 1      =     14.3 : 1.0\n",
      "                  V_flat = True                1 : 3      =     13.6 : 1.0\n",
      "                 V_worse = True                0 : 3      =     13.5 : 1.0\n",
      "                V_deeply = True                4 : 1      =     13.2 : 1.0\n",
      "              V_touching = True                4 : 1      =     13.2 : 1.0\n",
      "                  V_mess = True                0 : 4      =     13.0 : 1.0\n",
      "             V_contrived = True                0 : 3      =     12.1 : 1.0\n",
      "               V_lacking = True                0 : 3      =     12.1 : 1.0\n",
      "           V_pretentious = True                0 : 3      =     12.1 : 1.0\n",
      "                 V_tired = True                0 : 3      =     12.1 : 1.0\n",
      "            V_delightful = True                4 : 1      =     12.0 : 1.0\n",
      "                V_honest = True                4 : 1      =     12.0 : 1.0\n",
      "                  V_less = True                1 : 4      =     11.8 : 1.0\n",
      "                  V_ugly = True                0 : 2      =     11.8 : 1.0\n",
      "                V_French = False               3 : 1      =     11.8 : 1.0\n",
      "                  V_form = True                4 : 1      =     10.9 : 1.0\n",
      "              V_terrific = True                4 : 1      =     10.9 : 1.0\n",
      "                 V_bland = True                1 : 3      =     10.8 : 1.0\n",
      "            V_amateurish = True                0 : 3      =     10.6 : 1.0\n",
      "              V_horrible = True                0 : 3      =     10.6 : 1.0\n"
     ]
    }
   ],
   "source": [
    "#Again showing the most influential words\n",
    "classifier.show_most_informative_features(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7f00cf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross validation formula, this will take the featureset (reviews and accompoanying sentiment) and apply the testing, \n",
    "#training, and classifying and repeat the process for the amount of folds you give it.\n",
    "def cross_validation_accuracy(num_folds, featuresets):\n",
    "    subset_size = int(len(featuresets)/num_folds)\n",
    "    print('Each fold size:', subset_size)\n",
    "    accuracy_list = []\n",
    "    # iterate over the folds\n",
    "    for i in range(num_folds):\n",
    "        test_this_round = featuresets[(i*subset_size):][:subset_size]\n",
    "        train_this_round = featuresets[:(i*subset_size)] + featuresets[((i+1)*subset_size):]\n",
    "        # train using train_this_round\n",
    "        classifier = nltk.NaiveBayesClassifier.train(train_this_round)\n",
    "        # evaluate against test_this_round and save accuracy\n",
    "        accuracy_this_round = nltk.classify.accuracy(classifier, test_this_round)\n",
    "        print (i, accuracy_this_round)\n",
    "        accuracy_list.append(accuracy_this_round)\n",
    "    # find mean accuracy over all rounds\n",
    "    print ('mean accuracy', sum(accuracy_list) / num_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8262b23e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each fold size: 1706\n",
      "0 0.37807737397420865\n",
      "1 0.38452520515826494\n",
      "2 0.3862837045720985\n",
      "3 0.37807737397420865\n",
      "4 0.35873388042203985\n",
      "mean accuracy 0.3771395076201641\n"
     ]
    }
   ],
   "source": [
    "cross_validation_accuracy(5, featuresets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "68a083c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  |   3   1   2   4   0 |\n",
      "--+---------------------+\n",
      "3 |<108> 40  54  61  29 |\n",
      "1 |  42<106> 66  11  42 |\n",
      "2 |  46  45 <51> 17  14 |\n",
      "4 |  51  12  18 <65>  4 |\n",
      "0 |   7  45  22   3 <41>|\n",
      "--+---------------------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#This will help build the confusion matrix, comparing the predicted values with the trust values.\n",
    "#An example is shown\n",
    "goldlist = []\n",
    "predictedlist = []\n",
    "for (features, label) in test_set:\n",
    "    \tgoldlist.append(label)\n",
    "    \tpredictedlist.append(classifier.classify(features))\n",
    "cm = nltk.ConfusionMatrix(goldlist, predictedlist)\n",
    "print(cm.pretty_format(sort_by_count=True, truncate=9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3fbd7d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  |      3      1      2      4      0 |\n",
      "--+------------------------------------+\n",
      "3 | <10.8%>  4.0%   5.4%   6.1%   2.9% |\n",
      "1 |   4.2% <10.6%>  6.6%   1.1%   4.2% |\n",
      "2 |   4.6%   4.5%  <5.1%>  1.7%   1.4% |\n",
      "4 |   5.1%   1.2%   1.8%  <6.5%>  0.4% |\n",
      "0 |   0.7%   4.5%   2.2%   0.3%  <4.1%>|\n",
      "--+------------------------------------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Additionally, this can be made prettier with this code\n",
    "print(cm.pretty_format(sort_by_count=True, show_percents=True, truncate=9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "715b4083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute precision, recall and F1 for each label\n",
    "#  and for any number of labels\n",
    "# Input: list of gold labels, list of predicted labels (in same order)\n",
    "# Output:  prints precision, recall and F1 for each label\n",
    "def eval_measures(gold, predicted):\n",
    "    # get a list of labels\n",
    "    labels = list(set(gold))\n",
    "    # these lists have values for each label \n",
    "    recall_list = []\n",
    "    precision_list = []\n",
    "    F1_list = []\n",
    "    for lab in labels:\n",
    "        # for each label, compare gold and predicted lists and compute values\n",
    "        TP = FP = FN = TN = 0\n",
    "        for i, val in enumerate(gold):\n",
    "            if val == lab and predicted[i] == lab:  TP += 1\n",
    "            if val == lab and predicted[i] != lab:  FN += 1\n",
    "            if val != lab and predicted[i] == lab:  FP += 1\n",
    "            if val != lab and predicted[i] != lab:  TN += 1\n",
    "        # use these to compute recall, precision, F1\n",
    "        recall = TP / (TP + FP)\n",
    "        precision = TP / (TP + FN)\n",
    "        recall_list.append(recall)\n",
    "        precision_list.append(precision)\n",
    "        F1_list.append( 2 * (recall * precision) / (recall + precision))\n",
    "\n",
    "    # the evaluation measures in a table with one row per label\n",
    "    print('\\tPrecision\\tRecall\\t\\tF1')\n",
    "    # print measures for each label\n",
    "    for i, lab in enumerate(labels):\n",
    "        print(lab, '\\t', \"{:10.3f}\".format(precision_list[i]), \\\n",
    "          \"{:10.3f}\".format(recall_list[i]), \"{:10.3f}\".format(F1_list[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e89ae9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tPrecision\tRecall\t\tF1\n",
      "0 \t      0.347      0.315      0.331\n",
      "1 \t      0.397      0.427      0.412\n",
      "2 \t      0.295      0.242      0.266\n",
      "3 \t      0.370      0.425      0.396\n",
      "4 \t      0.433      0.414      0.423\n"
     ]
    }
   ],
   "source": [
    "eval_measures(goldlist, predictedlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7cb93087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.368\n",
      "Most Informative Features\n",
      "                   V_bad = True                0 : 4      =     24.7 : 1.0\n",
      "               V_minutes = True                0 : 4      =     21.2 : 1.0\n",
      "                 V_worst = True                0 : 3      =     18.8 : 1.0\n",
      "             V_wonderful = True                4 : 1      =     17.8 : 1.0\n",
      "                     V_? = True                2 : 4      =     17.7 : 1.0\n",
      "              V_touching = True                4 : 1      =     16.6 : 1.0\n",
      "            V_thoughtful = True                4 : 1      =     15.5 : 1.0\n",
      "                V_moving = True                4 : 0      =     14.7 : 1.0\n",
      "                  V_dull = True                0 : 3      =     14.7 : 1.0\n",
      "                  V_best = True                4 : 0      =     14.6 : 1.0\n",
      "                 V_worse = True                0 : 3      =     13.8 : 1.0\n",
      "                 V_heart = True                4 : 0      =     13.6 : 1.0\n",
      "                  V_mess = True                0 : 4      =     13.2 : 1.0\n",
      "             V_brilliant = True                4 : 1      =     13.2 : 1.0\n",
      "                V_deeply = True                4 : 1      =     13.2 : 1.0\n",
      "                V_stupid = True                0 : 2      =     12.7 : 1.0\n",
      "             V_contrived = True                0 : 3      =     12.4 : 1.0\n",
      "            V_filmmaking = True                4 : 2      =     12.3 : 1.0\n",
      "            V_engrossing = True                4 : 1      =     12.0 : 1.0\n",
      "             V_hilarious = True                4 : 1      =     12.0 : 1.0\n",
      "              V_terrific = True                4 : 1      =     12.0 : 1.0\n",
      "                  V_less = True                1 : 4      =     11.0 : 1.0\n",
      "                  V_flat = True                1 : 3      =     10.9 : 1.0\n",
      "            V_amateurish = True                0 : 3      =     10.9 : 1.0\n",
      "            V_depressing = True                0 : 3      =     10.9 : 1.0\n",
      "                V_devoid = True                0 : 3      =     10.9 : 1.0\n",
      "                V_entire = True                0 : 3      =     10.9 : 1.0\n",
      "              V_horrible = True                0 : 3      =     10.9 : 1.0\n",
      "               V_lacking = True                0 : 3      =     10.9 : 1.0\n",
      "                 V_money = True                0 : 3      =     10.9 : 1.0\n",
      "None\n",
      "Each fold size: 1706\n",
      "0 0.3886283704572098\n",
      "1 0.3810082063305979\n",
      "2 0.3798358733880422\n",
      "3 0.37924970691676435\n",
      "4 0.36811254396248533\n",
      "mean accuracy 0.3793669402110199\n",
      "\tPrecision\tRecall\t\tF1\n",
      "0 \t      0.343      0.383      0.362\n",
      "1 \t      0.432      0.413      0.422\n",
      "2 \t      0.252      0.252      0.252\n",
      "3 \t      0.349      0.367      0.358\n",
      "4 \t      0.472      0.430      0.450\n",
      "  |      1      3      2      4      0 |\n",
      "--+------------------------------------+\n",
      "1 | <11.4%>  3.0%   6.2%   1.2%   4.6% |\n",
      "3 |   4.4%  <8.8%>  6.4%   5.2%   0.4% |\n",
      "2 |   6.6%   4.8%  <5.2%>  2.0%   2.0% |\n",
      "4 |   0.6%   5.8%   0.8%  <6.8%>  0.4% |\n",
      "0 |   4.6%   1.6%   2.0%   0.6%  <4.6%>|\n",
      "--+------------------------------------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Default starting point. No filtering, no negation. Using all the tools created up to this point a baseline\n",
    "#accuracy using no filtering was created, cross validated, and shown with a confusion matrix. This is the\n",
    "#default classification and will be used to compare the experiments to.\n",
    "#Using only the top 2000 most frequently occuring words to train (experiment 2)\n",
    "def document_features(document, word_features):\n",
    "\tdocument_words = set(document)\n",
    "\tfeatures = {}\n",
    "\tfor word in word_features:\n",
    "\t\tfeatures['V_%s' % word] = (word in document_words)\n",
    "\treturn features\n",
    "biglist=\" \".join(Phraselist)\n",
    "fdist = FreqDist(word.lower() for word in word_tokenize(biglist))\n",
    "frequentwords=fdist.most_common(2000)\n",
    "word_features = [word for (word, freq) in frequentwords]\n",
    "phrasesent=list(zip(output.Phrase,output.Sentiment))\n",
    "phrasesent[0]\n",
    "tuples=[]\n",
    "somelist=[]\n",
    "hello=[]\n",
    "for review in phrasesent:\n",
    "    somelist=(review[0].split(), review[1])\n",
    "    hello=tuple(somelist)\n",
    "    tuples.append(hello)\n",
    "random.shuffle(tuples)\n",
    "featuresets = [(document_features(d, word_features), c) for (d,c) in tuples]\n",
    "train_set, test_set = featuresets[500:], featuresets[:500]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print (nltk.classify.accuracy(classifier, test_set))\n",
    "print(classifier.show_most_informative_features(30))\n",
    "\n",
    "def cross_validation_accuracy(num_folds, featuresets):\n",
    "    subset_size = int(len(featuresets)/num_folds)\n",
    "    print('Each fold size:', subset_size)\n",
    "    accuracy_list = []\n",
    "    # iterate over the folds\n",
    "    for i in range(num_folds):\n",
    "        test_this_round = featuresets[(i*subset_size):][:subset_size]\n",
    "        train_this_round = featuresets[:(i*subset_size)] + featuresets[((i+1)*subset_size):]\n",
    "        # train using train_this_round\n",
    "        classifier = nltk.NaiveBayesClassifier.train(train_this_round)\n",
    "        # evaluate against test_this_round and save accuracy\n",
    "        accuracy_this_round = nltk.classify.accuracy(classifier, test_this_round)\n",
    "        print (i, accuracy_this_round)\n",
    "        accuracy_list.append(accuracy_this_round)\n",
    "    # find mean accuracy over all rounds\n",
    "    print ('mean accuracy', sum(accuracy_list) / num_folds)\n",
    "    \n",
    "cross_validation_accuracy(5, featuresets)\n",
    "goldlist = []\n",
    "predictedlist = []\n",
    "for (features, label) in test_set:\n",
    "    \tgoldlist.append(label)\n",
    "    \tpredictedlist.append(classifier.classify(features))\n",
    "        \n",
    "cm = nltk.ConfusionMatrix(goldlist, predictedlist)\n",
    "def eval_measures(gold, predicted):\n",
    "    # get a list of labels\n",
    "    labels = list(set(gold))\n",
    "    # these lists have values for each label \n",
    "    recall_list = []\n",
    "    precision_list = []\n",
    "    F1_list = []\n",
    "    for lab in labels:\n",
    "        # for each label, compare gold and predicted lists and compute values\n",
    "        TP = FP = FN = TN = 0\n",
    "        for i, val in enumerate(gold):\n",
    "            if val == lab and predicted[i] == lab:  TP += 1\n",
    "            if val == lab and predicted[i] != lab:  FN += 1\n",
    "            if val != lab and predicted[i] == lab:  FP += 1\n",
    "            if val != lab and predicted[i] != lab:  TN += 1\n",
    "        # use these to compute recall, precision, F1\n",
    "        recall = TP / (TP + FP)\n",
    "        precision = TP / (TP + FN)\n",
    "        recall_list.append(recall)\n",
    "        precision_list.append(precision)\n",
    "        F1_list.append( 2 * (recall * precision) / (recall + precision))\n",
    "\n",
    "    # the evaluation measures in a table with one row per label\n",
    "    print('\\tPrecision\\tRecall\\t\\tF1')\n",
    "    # print measures for each label\n",
    "    for i, lab in enumerate(labels):\n",
    "        print(lab, '\\t', \"{:10.3f}\".format(precision_list[i]), \\\n",
    "          \"{:10.3f}\".format(recall_list[i]), \"{:10.3f}\".format(F1_list[i]))\n",
    "eval_measures(goldlist, predictedlist)\n",
    "print(cm.pretty_format(sort_by_count=True, show_percents=True, truncate=9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ea8b9025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.372\n",
      "Most Informative Features\n",
      "                   V_bad = True                0 : 4      =     43.3 : 1.0\n",
      "                     V_? = True                2 : 4      =     30.4 : 1.0\n",
      "                 V_worst = True                0 : 3      =     20.4 : 1.0\n",
      "             V_wonderful = True                4 : 1      =     16.7 : 1.0\n",
      "            V_thoughtful = True                4 : 1      =     15.5 : 1.0\n",
      "                  V_dull = True                0 : 3      =     14.6 : 1.0\n",
      "                  V_best = True                4 : 0      =     14.5 : 1.0\n",
      "             V_contrived = True                0 : 3      =     13.7 : 1.0\n",
      "                  V_less = True                1 : 4      =     12.9 : 1.0\n",
      "                V_stupid = True                0 : 2      =     12.7 : 1.0\n",
      "                 V_heart = True                4 : 0      =     12.6 : 1.0\n",
      "                  V_flat = True                1 : 3      =     12.3 : 1.0\n",
      "                 V_awful = True                0 : 3      =     12.3 : 1.0\n",
      "               V_lacking = True                0 : 3      =     12.3 : 1.0\n",
      "                 V_money = True                0 : 3      =     12.3 : 1.0\n",
      "           V_pretentious = True                0 : 3      =     12.3 : 1.0\n",
      "         V_coming-of-age = True                4 : 1      =     12.1 : 1.0\n",
      "                V_deeply = True                4 : 1      =     12.1 : 1.0\n",
      "            V_engrossing = True                4 : 1      =     12.1 : 1.0\n",
      "                V_honest = True                4 : 1      =     12.1 : 1.0\n",
      "              V_terrific = True                4 : 1      =     12.1 : 1.0\n",
      "                  V_mess = True                0 : 2      =     11.3 : 1.0\n",
      "               V_minutes = True                0 : 4      =     11.2 : 1.0\n",
      "                  V_form = True                4 : 1      =     10.9 : 1.0\n",
      "                  V_warm = True                4 : 1      =     10.9 : 1.0\n",
      "           V_fascinating = True                4 : 0      =     10.9 : 1.0\n",
      "            V_depressing = True                0 : 3      =     10.8 : 1.0\n",
      "                V_entire = True                0 : 3      =     10.8 : 1.0\n",
      "              V_horrible = True                0 : 3      =     10.8 : 1.0\n",
      "                  V_loud = True                0 : 3      =     10.8 : 1.0\n",
      "None\n",
      "Each fold size: 1706\n",
      "0 0.369284876905041\n",
      "1 0.3950762016412661\n",
      "2 0.3810082063305979\n",
      "3 0.3686987104337632\n",
      "4 0.3686987104337632\n",
      "mean accuracy 0.3765533411488863\n",
      "\tPrecision\tRecall\t\tF1\n",
      "0 \t      0.222      0.311      0.259\n",
      "1 \t      0.485      0.444      0.463\n",
      "2 \t      0.337      0.295      0.314\n",
      "3 \t      0.351      0.362      0.356\n",
      "4 \t      0.387      0.408      0.397\n",
      "  |      3      1      2      4      0 |\n",
      "--+------------------------------------+\n",
      "3 |  <9.4%>  4.0%   6.0%   6.0%   1.4% |\n",
      "1 |   3.2% <12.6%>  6.2%   1.0%   3.0% |\n",
      "2 |   6.0%   4.6%  <6.6%>  0.8%   1.6% |\n",
      "4 |   6.0%   1.2%   1.8%  <5.8%>  0.2% |\n",
      "0 |   1.4%   6.0%   1.8%   0.6%  <2.8%>|\n",
      "--+------------------------------------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Exact same except using the most common 4000 words instead of 2000\n",
    "biglist=\" \".join(Phraselist)\n",
    "fdist = FreqDist(word.lower() for word in word_tokenize(biglist))\n",
    "frequentwords=fdist.most_common(4000)\n",
    "word_features = [word for (word, freq) in frequentwords]\n",
    "phrasesent=list(zip(output.Phrase,output.Sentiment))\n",
    "phrasesent[0]\n",
    "tuples=[]\n",
    "somelist=[]\n",
    "hello=[]\n",
    "for review in phrasesent:\n",
    "    somelist=(review[0].split(), review[1])\n",
    "    hello=tuple(somelist)\n",
    "    tuples.append(hello)\n",
    "random.shuffle(tuples)\n",
    "featuresets = [(document_features(d, word_features), c) for (d,c) in tuples]\n",
    "train_set, test_set = featuresets[500:], featuresets[:500]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print (nltk.classify.accuracy(classifier, test_set))\n",
    "print(classifier.show_most_informative_features(30))\n",
    "cross_validation_accuracy(5, featuresets)\n",
    "goldlist = []\n",
    "predictedlist = []\n",
    "for (features, label) in test_set:\n",
    "    \tgoldlist.append(label)\n",
    "    \tpredictedlist.append(classifier.classify(features))\n",
    "        \n",
    "cm = nltk.ConfusionMatrix(goldlist, predictedlist)\n",
    "eval_measures(goldlist, predictedlist)\n",
    "print(cm.pretty_format(sort_by_count=True, show_percents=True, truncate=9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e8595622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.378\n",
      "Most Informative Features\n",
      "                   V_bad = True                0 : 4      =     39.7 : 1.0\n",
      "                     V_? = True                2 : 4      =     28.1 : 1.0\n",
      "                 V_worst = True                0 : 3      =     20.0 : 1.0\n",
      "             V_wonderful = True                4 : 1      =     16.5 : 1.0\n",
      "             V_beautiful = True                4 : 1      =     14.2 : 1.0\n",
      "            V_thoughtful = True                4 : 1      =     14.2 : 1.0\n",
      "                  V_best = True                4 : 0      =     13.9 : 1.0\n",
      "                  V_dull = True                0 : 3      =     13.7 : 1.0\n",
      "                V_stupid = True                0 : 2      =     12.7 : 1.0\n",
      "                  V_less = True                1 : 4      =     12.3 : 1.0\n",
      "                 V_heart = True                4 : 0      =     12.1 : 1.0\n",
      "                 V_awful = True                0 : 3      =     12.0 : 1.0\n",
      "             V_contrived = True                0 : 3      =     12.0 : 1.0\n",
      "                 V_money = True                0 : 3      =     12.0 : 1.0\n",
      "         V_coming-of-age = True                4 : 1      =     12.0 : 1.0\n",
      "                V_deeply = True                4 : 1      =     12.0 : 1.0\n",
      "            V_engrossing = True                4 : 1      =     12.0 : 1.0\n",
      "                V_honest = True                4 : 1      =     12.0 : 1.0\n",
      "              V_terrific = True                4 : 1      =     12.0 : 1.0\n",
      "                  V_warm = True                4 : 1      =     10.8 : 1.0\n",
      "                  V_mess = True                0 : 2      =     10.7 : 1.0\n",
      "               V_unfunny = True                0 : 2      =     10.7 : 1.0\n",
      "                V_entire = True                0 : 3      =     10.6 : 1.0\n",
      "              V_horrible = True                0 : 3      =     10.6 : 1.0\n",
      "                  V_loud = True                0 : 3      =     10.6 : 1.0\n",
      "               V_purpose = True                0 : 3      =     10.6 : 1.0\n",
      "               V_tedious = True                0 : 3      =     10.6 : 1.0\n",
      "                V_French = False               3 : 1      =     10.4 : 1.0\n",
      "                 V_grace = True                4 : 3      =     10.2 : 1.0\n",
      "              V_riveting = True                4 : 3      =     10.2 : 1.0\n",
      "Each fold size: 1706\n",
      "0 0.35580304806565066\n",
      "1 0.3757327080890973\n",
      "2 0.365767878077374\n",
      "3 0.3540445486518171\n",
      "4 0.34583821805392734\n",
      "mean accuracy 0.35943728018757326\n",
      "\tPrecision\tRecall\t\tF1\n",
      "0 \t      0.439      0.298      0.355\n",
      "1 \t      0.378      0.484      0.424\n",
      "2 \t      0.315      0.286      0.299\n",
      "3 \t      0.337      0.425      0.376\n",
      "4 \t      0.486      0.369      0.420\n",
      "  |      3      1      2      4      0 |\n",
      "--+------------------------------------+\n",
      "3 |  <9.6%>  3.0%   5.6%   7.7%   2.6% |\n",
      "1 |   3.9% <10.4%>  5.6%   2.1%   5.5% |\n",
      "2 |   3.6%   3.7%  <5.6%>  2.0%   2.9% |\n",
      "4 |   4.6%   0.9%   1.3%  <7.2%>  0.8% |\n",
      "0 |   0.9%   3.5%   1.5%   0.5%  <5.0%>|\n",
      "--+------------------------------------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#using negation words in the word_features\n",
    "biglist=\" \".join(Phraselist)\n",
    "fdist = FreqDist(word.lower() for word in word_tokenize(biglist))\n",
    "frequentwords=fdist.most_common(2000)\n",
    "word_features = [word for (word, freq) in frequentwords]\n",
    "import re\n",
    "negationwords = [\"can't\", \"wasn't\" 'no', 'not', 'never', 'none', 'nowhere', \n",
    "                 'nothing', 'noone', 'rather', 'hardly', 'scarcely', 'rarely', \n",
    "                 'seldom', 'neither', 'nor']\n",
    "def NOT_features(document, word_features, negationwords):\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['V_{}'.format(word)] = False\n",
    "        features['V_NOT{}'.format(word)] = False\n",
    "    # go through document words in order\n",
    "    for i in range(0, len(document)):\n",
    "        word = document[i]\n",
    "        if ((i + 1) < len(document)) and ((word in negationwords) or (word.endswith(\"n't\"))):\n",
    "            i += 1\n",
    "            features['V_NOT{}'.format(document[i])] = (document[i] in word_features)\n",
    "        else:\n",
    "            features['V_{}'.format(word)] = (word in word_features)\n",
    "    return features\n",
    "\n",
    "NOT_featuresets = [(NOT_features(d, word_features, negationwords), c) for (d, c) in tuples]\n",
    "train_set, test_set = NOT_featuresets[1000:], NOT_featuresets[:1000]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))\n",
    "classifier.show_most_informative_features(30)\n",
    "cross_validation_accuracy(5, NOT_featuresets)\n",
    "goldlist = []\n",
    "predictedlist = []\n",
    "for (features, label) in test_set:\n",
    "    \tgoldlist.append(label)\n",
    "    \tpredictedlist.append(classifier.classify(features))\n",
    "        \n",
    "cm = nltk.ConfusionMatrix(goldlist, predictedlist)\n",
    "eval_measures(goldlist, predictedlist)\n",
    "print(cm.pretty_format(sort_by_count=True, show_percents=True, truncate=9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7aeb3f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Going to try bigrams now, the 10,000 most frequent bigrams were collected and will be used with the below function\n",
    "from nltk.collocations import *\n",
    "from nltk.corpus import sentence_polarity\n",
    "biglist=\" \".join(Phraselist)\n",
    "fdist = FreqDist(word.lower() for word in word_tokenize(biglist))\n",
    "frequentwords=fdist.most_common(4000)\n",
    "word_features = [word for (word, freq) in frequentwords]\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "all_words_list = [word for (sent,cat) in tuples for word in sent]\n",
    "finder = BigramCollocationFinder.from_words(all_words_list)\n",
    "bigram_features = finder.nbest(bigram_measures.chi_sq, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e80a750e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bigram function that makes a feature set with both the words in the featurewords set and with the bigrams from above.\n",
    "def bigram_document_features(document, word_features, bigram_features):\n",
    "    document_words = set(document)\n",
    "    document_bigrams = nltk.bigrams(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['V_{}'.format(word)] = (word in document_words)\n",
    "    for bigram in bigram_features:\n",
    "        features['B_{}_{}'.format(bigram[0], bigram[1])] = (bigram in document_bigrams)    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dbc6f7a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.382\n",
      "Most Informative Features\n",
      "                   V_bad = True                0 : 4      =     39.7 : 1.0\n",
      "                     V_? = True                2 : 4      =     28.1 : 1.0\n",
      "                 V_worst = True                0 : 3      =     20.0 : 1.0\n",
      "             V_wonderful = True                4 : 1      =     16.5 : 1.0\n",
      "             V_beautiful = True                4 : 1      =     14.2 : 1.0\n",
      "            V_thoughtful = True                4 : 1      =     14.2 : 1.0\n",
      "                  V_best = True                4 : 0      =     13.9 : 1.0\n",
      "                  V_dull = True                0 : 3      =     13.7 : 1.0\n",
      "                V_stupid = True                0 : 2      =     12.7 : 1.0\n",
      "                  V_less = True                1 : 4      =     12.3 : 1.0\n",
      "                 V_heart = True                4 : 0      =     12.1 : 1.0\n",
      "                 V_awful = True                0 : 3      =     12.0 : 1.0\n",
      "             V_contrived = True                0 : 3      =     12.0 : 1.0\n",
      "                 V_money = True                0 : 3      =     12.0 : 1.0\n",
      "         V_coming-of-age = True                4 : 1      =     12.0 : 1.0\n",
      "                V_deeply = True                4 : 1      =     12.0 : 1.0\n",
      "            V_engrossing = True                4 : 1      =     12.0 : 1.0\n",
      "                V_honest = True                4 : 1      =     12.0 : 1.0\n",
      "              V_terrific = True                4 : 1      =     12.0 : 1.0\n",
      "                  V_warm = True                4 : 1      =     10.8 : 1.0\n",
      "                  V_mess = True                0 : 2      =     10.7 : 1.0\n",
      "               V_unfunny = True                0 : 2      =     10.7 : 1.0\n",
      "                V_entire = True                0 : 3      =     10.6 : 1.0\n",
      "              V_horrible = True                0 : 3      =     10.6 : 1.0\n",
      "                  V_loud = True                0 : 3      =     10.6 : 1.0\n",
      "               V_purpose = True                0 : 3      =     10.6 : 1.0\n",
      "               V_tedious = True                0 : 3      =     10.6 : 1.0\n",
      "                 V_grace = True                4 : 3      =     10.2 : 1.0\n",
      "              V_riveting = True                4 : 3      =     10.2 : 1.0\n",
      "              V_stunning = True                4 : 3      =     10.2 : 1.0\n",
      "Each fold size: 1706\n",
      "0 0.369284876905041\n",
      "1 0.3950762016412661\n",
      "2 0.3810082063305979\n",
      "3 0.3686987104337632\n",
      "4 0.3686987104337632\n",
      "mean accuracy 0.3765533411488863\n",
      "\tPrecision\tRecall\t\tF1\n",
      "0 \t      0.228      0.277      0.250\n",
      "1 \t      0.458      0.462      0.460\n",
      "2 \t      0.320      0.260      0.287\n",
      "3 \t      0.396      0.414      0.405\n",
      "4 \t      0.405      0.426      0.415\n",
      "  |      3      1      2      4      0 |\n",
      "--+------------------------------------+\n",
      "3 | <11.3%>  4.1%   6.3%   5.4%   1.4% |\n",
      "1 |   4.4% <12.6%>  6.5%   1.1%   2.9% |\n",
      "2 |   4.6%   4.4%  <5.7%>  1.2%   1.9% |\n",
      "4 |   5.8%   1.1%   1.3%  <6.0%>  0.6% |\n",
      "0 |   1.2%   5.1%   2.1%   0.4%  <2.6%>|\n",
      "--+------------------------------------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Bigram Accuracy. This was done using the tools from before, however this time the featureset includes the bigrams\n",
    "bigram_featuresets = [(bigram_document_features(d, word_features, bigram_features), c) for (d, c) in tuples]\n",
    "train_set, test_set = bigram_featuresets[1000:], bigram_featuresets[:1000]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "nltk.classify.accuracy(classifier, test_set)\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))\n",
    "classifier.show_most_informative_features(30)\n",
    "cross_validation_accuracy(5, featuresets)\n",
    "goldlist = []\n",
    "predictedlist = []\n",
    "for (features, label) in test_set:\n",
    "    \tgoldlist.append(label)\n",
    "    \tpredictedlist.append(classifier.classify(features))\n",
    "        \n",
    "cm = nltk.ConfusionMatrix(goldlist, predictedlist)\n",
    "eval_measures(goldlist, predictedlist)\n",
    "print(cm.pretty_format(sort_by_count=True, show_percents=True, truncate=9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "08c2bd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the necessary SKLearn packages for SVM\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2a594b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# Create feature vectors\n",
    "vectorizer = TfidfVectorizer(min_df = 5,\n",
    "                             max_df = 0.8,\n",
    "                             sublinear_tf = True,\n",
    "                             use_idf = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c1d3510d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomize and pull training and testing phrases with their accompanying sentiments\n",
    "randomizedoutput=output\n",
    "training=randomizedoutput[:7000]\n",
    "testing=randomizedoutput[7000:]\n",
    "train_vectors = vectorizer.fit_transform(training[\"Phrase\"])\n",
    "test_vectors = vectorizer.transform(testing[\"Phrase\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "42413057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:  {'precision': 0.4065934065934066, 'recall': 0.19072164948453607, 'f1-score': 0.2596491228070175, 'support': 194}\n",
      "1:  {'precision': 0.40794223826714804, 'recall': 0.578005115089514, 'f1-score': 0.47830687830687835, 'support': 391}\n",
      "2:  {'precision': 0.28879310344827586, 'recall': 0.22866894197952217, 'f1-score': 0.2552380952380952, 'support': 293}\n",
      "3:  {'precision': 0.43100189035916825, 'recall': 0.5428571428571428, 'f1-score': 0.4805057955742887, 'support': 420}\n",
      "4:  {'precision': 0.5161290322580645, 'recall': 0.27586206896551724, 'f1-score': 0.3595505617977528, 'support': 232}\n"
     ]
    }
   ],
   "source": [
    "#An svm was fun (linear) on the training data. The precision for each sentiment guess is also included\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "# Perform classification with SVM, kernel=linear\n",
    "classifier_linear = svm.SVC(kernel='linear')\n",
    "classifier_linear.fit(train_vectors, training['Sentiment'])\n",
    "prediction_linear = classifier_linear.predict(test_vectors)\n",
    "# results\n",
    "report = classification_report(testing['Sentiment'], prediction_linear, output_dict=True)\n",
    "print('0: ', report['0'])\n",
    "print('1: ', report['1'])\n",
    "print('2: ', report['2'])\n",
    "print('3: ', report['3'])\n",
    "print('4: ', report['4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "05d761fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130213    3\n",
       "130217    3\n",
       "130229    0\n",
       "130240    2\n",
       "130245    3\n",
       "         ..\n",
       "155984    2\n",
       "155997    2\n",
       "156021    1\n",
       "156031    1\n",
       "156039    2\n",
       "Name: Sentiment, Length: 1530, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prediction_linear)\n",
    "testing[\"Sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f0a6bb4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tPrecision\tRecall\t\tF1\n",
      "0 \t      0.191      0.407      0.260\n",
      "1 \t      0.578      0.408      0.478\n",
      "2 \t      0.229      0.289      0.255\n",
      "3 \t      0.543      0.431      0.481\n",
      "4 \t      0.276      0.516      0.360\n",
      "  |      3      1      2      4      0 |\n",
      "--+------------------------------------+\n",
      "3 | <14.9%>  5.5%   3.9%   2.7%   0.5% |\n",
      "1 |   4.2% <14.8%>  4.1%   0.4%   2.1% |\n",
      "2 |   5.5%   7.8%  <4.4%>  0.6%   0.8% |\n",
      "4 |   7.7%   1.6%   1.5%  <4.2%>  0.1% |\n",
      "0 |   2.2%   6.5%   1.3%   0.3%  <2.4%>|\n",
      "--+------------------------------------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Plugging in the above functions to create a confusion matrix and cross validation for the SVM predicted sentiments\n",
    "cm = nltk.ConfusionMatrix(testing[\"Sentiment\"], prediction_linear)\n",
    "eval_measures(testing[\"Sentiment\"], prediction_linear)\n",
    "print(cm.pretty_format(sort_by_count=True, show_percents=True, truncate=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "599a3db3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The number of FixedLocator locations (5), usually from a call to set_ticks, does not match the number of ticklabels (2).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/5r/sp0kcnm15zb_sy3215s143_r0000gn/T/ipykernel_15249/3183884954.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mconfusion_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Sentiment\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_linear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mcm_display\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConfusionMatrixDisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mcm_display\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_plot/confusion_matrix.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, include_values, cmap, xticks_rotation, values_format, ax, colorbar)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcolorbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolorbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         ax.set(\n\u001b[0m\u001b[1;32m    164\u001b[0m             \u001b[0mxticks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0myticks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mArtist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"set\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__qualname__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{cls.__qualname__}.set\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mset\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1162\u001b[0m         \u001b[0;31m# module.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1164\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcontextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, props)\u001b[0m\n\u001b[1;32m   1064\u001b[0m                         raise AttributeError(f\"{type(self).__name__!r} object \"\n\u001b[1;32m   1065\u001b[0m                                              f\"has no property {k!r}\")\n\u001b[0;32m-> 1066\u001b[0;31m                     \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1067\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpchanged\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mget_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mowner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_set_ticklabels\u001b[0;34m(self, labels, fontdict, minor, **kwargs)\u001b[0m\n\u001b[1;32m   1796\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfontdict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1797\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfontdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1798\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ticklabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mminor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1800\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_tick_locations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mticks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mset_ticklabels\u001b[0;34m(self, ticklabels, minor, **kwargs)\u001b[0m\n\u001b[1;32m   1718\u001b[0m             \u001b[0;31m# remove all tick labels, so only error for > 0 ticklabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1719\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticklabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticklabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1720\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m   1721\u001b[0m                     \u001b[0;34m\"The number of FixedLocator locations\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1722\u001b[0m                     \u001b[0;34mf\" ({len(locator.locs)}), usually from a call to\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The number of FixedLocator locations (5), usually from a call to set_ticks, does not match the number of ticklabels (2)."
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Finally, plotting the resuling SVM results using matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "from sklearn import metrics\n",
    "confusion_matrix = metrics.confusion_matrix(testing[\"Sentiment\"], prediction_linear)\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [False, True])\n",
    "cm_display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6eedc86a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4065359477124183"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SVM model accuracy\n",
    "Accuracy = metrics.accuracy_score(testing[\"Sentiment\"], prediction_linear)\n",
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d307983d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc2649f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d3ee1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
